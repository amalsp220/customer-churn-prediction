# ðŸ”® Customer Churn Prediction

> A comprehensive Machine Learning project to predict customer churn using advanced classification algorithms and deployment-ready architecture.

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-orange)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ðŸ“Š Project Overview

Customer churn is a critical business metric. This project implements a complete ML pipeline to:
- Predict which customers are likely to churn
- Identify key factors influencing churn
- Provide actionable insights for customer retention strategies

**Key Features:**
- âœ… Exploratory Data Analysis with interactive visualizations
- âœ… Advanced feature engineering and selection
- âœ… Multiple ML models comparison (Random Forest, XGBoost, LightGBM)
- âœ… Hyperparameter tuning using GridSearchCV
- âœ… Model interpretability with SHAP values
- âœ… Deployment-ready Flask API
- âœ… Comprehensive evaluation metrics

## ðŸŽ¯ Business Impact

- **Accuracy**: 85%+ prediction accuracy
- **Early Detection**: Identify at-risk customers 30 days in advance
- **ROI**: Potential to reduce churn by 15-20%

## ðŸ—‚ï¸ Project Structure

```
customer-churn-prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Original datasets
â”‚   â””â”€â”€ processed/           # Cleaned and engineered features
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb        # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_Feature_Engineering.ipynb
â”‚   â””â”€â”€ 03_Model_Training.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â””â”€â”€ model_evaluation.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pkl      # Trained model
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py              # Flask API
â”‚   â””â”€â”€ templates/          # Web interface
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸ› ï¸ Tech Stack

- **Data Processing**: Pandas, NumPy
- **Visualization**: Matplotlib, Seaborn, Plotly
- **Machine Learning**: scikit-learn, XGBoost, LightGBM
- **Model Interpretability**: SHAP, LIME
- **Deployment**: Flask, Docker
- **Version Control**: Git, DVC

## ðŸ“ˆ Methodology

### 1. Data Preprocessing
- Handling missing values
- Outlier detection and treatment
- Feature scaling and normalization
- Encoding categorical variables

### 2. Feature Engineering
- Customer tenure analysis
- Service usage patterns
- Payment behavior indicators
- Customer interaction metrics

### 3. Model Development
- **Baseline Models**: Logistic Regression, Decision Trees
- **Advanced Models**: Random Forest, XGBoost, LightGBM
- **Ensemble Methods**: Voting Classifier, Stacking

### 4. Model Evaluation
- Accuracy, Precision, Recall, F1-Score
- ROC-AUC curve analysis
- Confusion matrix
- Cross-validation scores

## ðŸš€ Getting Started

### Prerequisites
```bash
python >= 3.8
pip >= 21.0
```

### Installation

1. Clone the repository
```bash
git clone https://github.com/amalsp220/customer-churn-prediction.git
cd customer-churn-prediction
```

2. Install dependencies
```bash
pip install -r requirements.txt
```

3. Run Jupyter notebooks
```bash
jupyter notebook
```

## ðŸ’¡ Usage

### Training the Model
```python
from src.model_training import train_model

model = train_model(data_path='data/processed/train.csv')
```

### Making Predictions
```python
from src.model_evaluation import predict_churn

prediction = predict_churn(customer_data)
print(f"Churn Probability: {prediction}%")
```

### Running the Flask API
```bash
cd app
python app.py
```
Visit `http://localhost:5000` to access the web interface.

## ðŸ“Š Results

| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|-------|----------|-----------|--------|----------|----------|
| Logistic Regression | 79.2% | 75.3% | 68.1% | 71.5% | 0.84 |
| Random Forest | 84.5% | 82.1% | 79.6% | 80.8% | 0.91 |
| XGBoost | **86.3%** | **84.7%** | **82.3%** | **83.5%** | **0.93** |
| LightGBM | 85.8% | 83.5% | 81.2% | 82.3% | 0.92 |

### Feature Importance
Top 5 features contributing to churn:
1. Contract type (month-to-month)
2. Tenure (< 6 months)
3. Total charges
4. Tech support availability
5. Payment method

## ðŸŽ“ Key Learnings

- Imbalanced dataset handling using SMOTE
- Feature engineering significantly improved model performance
- XGBoost outperformed other algorithms for this use case
- SHAP values provided actionable business insights

## ðŸ”® Future Enhancements

- [ ] Real-time prediction pipeline
- [ ] A/B testing framework
- [ ] Integration with CRM systems
- [ ] Deep learning models (Neural Networks)
- [ ] Automated retraining pipeline
- [ ] Customer segmentation analysis

## ðŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ðŸ“§ Contact

**Amal S P**
- GitHub: [@amalsp220](https://github.com/amalsp220)
- LinkedIn: [Connect with me](https://www.linkedin.com/in/amalsp220)
- Email: your.email@example.com

---

â­ If you found this project helpful, please give it a star!
